{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openstack import connection\n",
    "import paramiko\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Instance Name :bvb123\n",
      "1 Large     3GB RAM \n",
      "2 Medium    2GB RAM\n",
      "3 Small     1GB RAM\n",
      "Select your choice for flavour3\n"
     ]
    }
   ],
   "source": [
    "name=input(\"Enter Instance Name :\")\n",
    "print(\"1 Large     3GB RAM \\n2 Medium    2GB RAM\\n3 Small     1GB RAM\")\n",
    "\n",
    "img='451d7061-8c69-4e07-8a97-3b1b866e372d'\n",
    "#ubuntu_14='49618a75-d9dc-49f7-8cd5-7e556b6b1457'\n",
    "while True:\n",
    "    flavour=int(input(\"Select your choice for flavour\"))\n",
    "    if flavour==1:\n",
    "        #img=cirros\n",
    "        input_ram=3\n",
    "        flavourName='Large'\n",
    "        break\n",
    "    elif flavour==2:\n",
    "        #img=cirros\n",
    "        input_ram=2\n",
    "        flavourName='hadoop'\n",
    "        break\n",
    "    elif flavour==3:\n",
    "        #img=cirros\n",
    "        input_ram=1\n",
    "        flavourName='f1'\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid Input!!!Re enter :\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to run command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cmp='''source creds && openstack host show'''\n",
    "def sshmaster(address,cmp):\n",
    "    mastervmhd1 = paramiko.SSHClient()\n",
    "    mastervmhd1.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    print(\"connecting\")\n",
    "    mastervmhd1.connect(address, \"22\", \"ubuntu\", \"root1234\")\n",
    "    print(\"connected\")\n",
    "    stdin, stdout, stderr = mastervmhd1.exec_command(cmp,get_pty=True)\n",
    "    for line in iter(stdout.readline, \"\"):\n",
    "        std.append(line)\n",
    "    \n",
    "    print(stdout.read())\n",
    "    print(stderr.read())\n",
    "    #std=stdout.readlines()\n",
    "    print(std)\n",
    "    mastervmhd1.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Compute 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting\n",
      "connected\n",
      "b''\n",
      "b''\n",
      "['+-----------+----------------------------------+-----+-----------+---------+\\r\\n', '| Host      | Project                          | CPU | Memory MB | Disk GB |\\r\\n', '+-----------+----------------------------------+-----+-----------+---------+\\r\\n', '| compute01 | (total)                          |   2 |      3943 |      45 |\\r\\n', '| compute01 | (used_now)                       |   2 |      4608 |      10 |\\r\\n', '| compute01 | (used_max)                       |   2 |      4096 |      10 |\\r\\n', '| compute01 | 2448c5574f994284a0de2604962a55a0 |   2 |      4096 |      10 |\\r\\n', '+-----------+----------------------------------+-----+-----------+---------+\\r\\n']\n"
     ]
    }
   ],
   "source": [
    "std=[]\n",
    "sshmaster(\"192.168.31.2\",\"source creds && openstack host show compute01\")\n",
    "t1=std[3].split()\n",
    "t2=std[4].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=float(t1[-4])-512\n",
    "b=float(t2[-4])\n",
    "freeRam1=(a-b)\n",
    "freeCpu1=int(t1[-6])-int(t2[-6])\n",
    "freeRam1=float(freeRam1/1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting\n",
      "connected\n",
      "b''\n",
      "b''\n",
      "['+-----------+----------------------------------+-----+-----------+---------+\\r\\n', '| Host      | Project                          | CPU | Memory MB | Disk GB |\\r\\n', '+-----------+----------------------------------+-----+-----------+---------+\\r\\n', '| compute02 | (total)                          |   2 |      7975 |      45 |\\r\\n', '| compute02 | (used_now)                       |   5 |      9728 |      35 |\\r\\n', '| compute02 | (used_max)                       |   5 |      9216 |      35 |\\r\\n', '| compute02 | 2448c5574f994284a0de2604962a55a0 |   5 |      9216 |      35 |\\r\\n', '+-----------+----------------------------------+-----+-----------+---------+\\r\\n']\n"
     ]
    }
   ],
   "source": [
    "std=[]\n",
    "sshmaster(\"192.168.31.2\",\"source creds && openstack host show compute02\")\n",
    "t1=std[3].split()\n",
    "t2=std[4].split()\n",
    "a=float(t1[-4])-512\n",
    "b=float(t2[-4])\n",
    "freeRam2=(a-b)\n",
    "freeCpu2=int(t1[-6])-int(t2[-6])\n",
    "freeRam2=round(float(freeRam2/1024),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting\n",
      "connected\n",
      "b''\n",
      "b''\n",
      "['+-----------+----------------------------------+-----+-----------+---------+\\r\\n', '| Host      | Project                          | CPU | Memory MB | Disk GB |\\r\\n', '+-----------+----------------------------------+-----+-----------+---------+\\r\\n', '| compute03 | (total)                          |   2 |      7975 |      45 |\\r\\n', '| compute03 | (used_now)                       |   5 |     10752 |      25 |\\r\\n', '| compute03 | (used_max)                       |   5 |     10240 |      25 |\\r\\n', '| compute03 | 2448c5574f994284a0de2604962a55a0 |   5 |     10240 |      25 |\\r\\n', '+-----------+----------------------------------+-----+-----------+---------+\\r\\n']\n"
     ]
    }
   ],
   "source": [
    "std=[]\n",
    "sshmaster(\"192.168.31.2\",\"source creds && openstack host show compute03\")\n",
    "t1=std[3].split()\n",
    "t2=std[4].split()\n",
    "a=float(t1[-4])-512\n",
    "b=float(t2[-4])\n",
    "freeRam3=(a-b)\n",
    "freeCpu3=int(t1[-6])-int(t2[-6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeRam3=round(float(freeRam3/1024),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting\n",
      "connected\n",
      "b''\n",
      "b''\n",
      "['+-----------+----------------------------------+-----+-----------+---------+\\r\\n', '| Host      | Project                          | CPU | Memory MB | Disk GB |\\r\\n', '+-----------+----------------------------------+-----+-----------+---------+\\r\\n', '| compute04 | (total)                          |   8 |      7975 |      45 |\\r\\n', '| compute04 | (used_now)                       |   5 |     10752 |      25 |\\r\\n', '| compute04 | (used_max)                       |   5 |     10240 |      25 |\\r\\n', '| compute04 | 2448c5574f994284a0de2604962a55a0 |   5 |     10240 |      25 |\\r\\n', '+-----------+----------------------------------+-----+-----------+---------+\\r\\n']\n"
     ]
    }
   ],
   "source": [
    "std=[]\n",
    "sshmaster(\"192.168.31.2\",\"source creds && openstack host show compute04\")\n",
    "t1=std[3].split()\n",
    "t2=std[4].split()\n",
    "a=float(t1[-4])-512\n",
    "b=float(t2[-4])\n",
    "freeRam4=(a-b)\n",
    "freeCpu4=int(t1[-6])-int(t2[-6])\n",
    "freeRam4=round(float(freeRam4/1024),1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting\n",
      "connected\n",
      "b''\n",
      "b''\n",
      "['+-----------+----------------------------------+-----+-----------+---------+\\r\\n', '| Host      | Project                          | CPU | Memory MB | Disk GB |\\r\\n', '+-----------+----------------------------------+-----+-----------+---------+\\r\\n', '| compute05 | (total)                          |   2 |      7975 |      45 |\\r\\n', '| compute05 | (used_now)                       |   2 |      4608 |      10 |\\r\\n', '| compute05 | (used_max)                       |   2 |      4096 |      10 |\\r\\n', '| compute05 | 2448c5574f994284a0de2604962a55a0 |   2 |      4096 |      10 |\\r\\n', '+-----------+----------------------------------+-----+-----------+---------+\\r\\n']\n"
     ]
    }
   ],
   "source": [
    "std=[]\n",
    "sshmaster(\"192.168.31.2\",\"source creds && openstack host show compute05\")\n",
    "t1=std[3].split()\n",
    "t2=std[4].split()\n",
    "a=float(t1[-4])-512\n",
    "b=float(t2[-4])\n",
    "freeRam5=(a-b)\n",
    "freeCpu5=int(t1[-6])-int(t2[-6])\n",
    "freeRam5=round(float(freeRam5/1024),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "availableRam=[(freeRam1),(freeRam2),(freeRam3),freeRam4,freeRam5]\n",
    "availableCpu=[freeCpu1,freeCpu2,freeCpu3,freeCpu4,freeCpu5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocateVM(inputRam):\n",
    "    eligible=pd.DataFrame(columns=['Compute','Available RAM'])\n",
    "    \n",
    "    minSpace=0\n",
    "    if freeCpu1>0:\n",
    "        #print(freeCpu1)\n",
    "        if inputRam<freeRam1:\n",
    "            #print(\"Free RAM in COMPUTE1 \",freeRam1)\n",
    "            eligible=eligible.append({'Compute':'compute01','Available RAM':freeRam1},ignore_index=True)\n",
    "            #eligible[1][0]=freeRam1\n",
    "        #df.append({'name': 'Zed', 'age': 9, 'height': 2}, ignore_index=True)\n",
    "    \n",
    "    if freeCpu2>0:\n",
    "        #print(freeCpu2)\n",
    "        if inputRam<freeRam2:\n",
    "            #print(\"Free RAM in COMPUTE 2 \",freeRam2)\n",
    "            eligible=eligible.append({'Compute':'compute02','Available RAM':freeRam2},ignore_index=True)\n",
    "        \n",
    "    #Series(42,index=[1,2],name='col')\n",
    "    if freeCpu3>0:\n",
    "        print(\"Compute 3 cpu \",freeCpu3)\n",
    "        if inputRam<freeRam3:\n",
    "            #print(\"Free RAM in COMPUTE 3\",freeRam3)\n",
    "            eligible=eligible.append({'Compute':'compute03','Available RAM':freeRam3},ignore_index=True)\n",
    "    if freeCpu4>0:\n",
    "        #print(freeCpu4)\n",
    "        if inputRam<freeRam4:\n",
    "            print(\"Free RAM in COMPUTE 4 \",freeRam4)\n",
    "            eligible=eligible.append({'Compute':'compute04','Available RAM':freeRam4},ignore_index=True)\n",
    "        \n",
    "    #Series(42,index=[1,2],name='col')\n",
    "    if freeCpu5>0:\n",
    "        #print(\"Compute 3 cpu \",freeCpu3)\n",
    "        if inputRam<freeRam5:\n",
    "            print(\"Free RAM in COMPUTE 5 \",freeRam5)\n",
    "            eligible=eligible.append({'Compute':'compute05','Available RAM':freeRam5},ignore_index=True)    \n",
    "    print(\"Eligibility dataframe:\\n\")\n",
    "    print(eligible)\n",
    "    return eligible\n",
    "    #host = eligible.index(min(eligible)) \n",
    "    #host=host+1\n",
    "    #print(host)\n",
    "    #if host==1:\n",
    "     #   sshmaster(nova boot --flavor hadoop --image a0cdbd78-4b34-4f35-b6e9-89d822b79142 --nic net-id=467a06de-fc2c-4fe9-876c-cbec7fe29149 --key-name i4key  --availability-zone nova:compute01 \"+vm_name+\"\")\n",
    "    #elif host==2:\n",
    "     #   sshmaster(nova boot --flavor hadoop --image a0cdbd78-4b34-4f35-b6e9-89d822b79142 --nic net-id=467a06de-fc2c-4fe9-876c-cbec7fe29149 --key-name i4key  --availability-zone nova:compute02 \"+vm_name+\"\")\n",
    "    #elif host==3:\n",
    "     #   sshmaster(nova boot --flavor hadoop --image a0cdbd78-4b34-4f35-b6e9-89d822b79142 --nic net-id=467a06de-fc2c-4fe9-876c-cbec7fe29149 --key-name i4key  --availability-zone nova:compute03 \"+vm_name+\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligibility dataframe:\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Compute, Available RAM]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "availableCpuArray=np.array([freeCpu1,freeCpu2,freeCpu3])\n",
    "if(not np.any(availableCpuArray)):\n",
    "    print(\"No available hosts\")\n",
    "else:\n",
    "    eligible=allocateVM(input_ram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch present cpu utilization values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Instance name, ID, Compute]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from openstack import connection\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "auth_args = {\n",
    "    'auth_url': 'http://192.168.31.2:5000/identity/v3',\n",
    "    'project_name': 'admin',\n",
    "    'username': 'admin',\n",
    "    'password': 'admin_pass',\n",
    "    'user_domain_id': 'default',\n",
    "    'project_domain_id': 'default',\n",
    "}\n",
    "l1=[]\n",
    "l2=[]\n",
    "l3=[]\n",
    "connection_to_controller = connection.Connection(**auth_args)\n",
    "auth_token = connection_to_controller.authorize()\n",
    "url = \"http://192.168.31.2:8774/v2.1/servers\" #REST api \n",
    "weekly_data_json = requests.get(url=url, headers={'X-Auth-token': auth_token, 'Content-type': 'application/json'}).json() #GET request to fetch json data from ceilometer\n",
    "count = 0\n",
    "for instances in weekly_data_json[\"servers\"]:\n",
    "    url_id = \"http://192.168.31.2:8774/v2.1/servers/{}\".format(instances['id'])\n",
    "    compute_json = requests.get(url=url_id, headers={'X-Auth-token': auth_token, 'Content-type': 'application/json'}).json()\n",
    "   # print(compute_json)\n",
    "    #computedf=pd.DataFrame(compute_json)\n",
    "    #print(computedf['server'][15:16][0])\n",
    "    #x=pd.DataFrame(computedf['server'][15:16][0])\n",
    "   # print(x['id'])\n",
    "    #print(instances['flavor'])\n",
    "    #print(instances[\"name\"] + \"------>\" + instances['id'] + \"------>\" + compute_json['server']['OS-EXT-SRV-ATTR:host'])\n",
    "    if ( compute_json['server']['OS-EXT-SRV-ATTR:host'] in eligible['Compute'].tolist()):\n",
    "        l1.append(instances[\"name\"])\n",
    "        l2.append(instances['id'])\n",
    "        l3.append(compute_json['server']['OS-EXT-SRV-ATTR:host'])\n",
    "        count += 1\n",
    "    #print(\"************************\")\n",
    "   # print(\"no. of instances {}\".format(count))\n",
    "    df=pd.DataFrame(columns=['Instance name','ID','Compute'])\n",
    "    df['Instance name']=l1\n",
    "    df['ID']=l2\n",
    "    df['Compute']=l3\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute1=[]\n",
    "compute2=[]\n",
    "compute3=[]\n",
    "compute4=[]\n",
    "compute5=[]\n",
    "for i in range(len(df)):\n",
    "    j=i+1\n",
    "    \n",
    "    if df['Compute'][i:j][i]=='compute01':\n",
    "        compute1.append(df['ID'][i:j][i])\n",
    "        #print(i,j,df['Compute'][i:j][i],df['ID'][i:j][i])\n",
    "    \n",
    "    elif df['Compute'][i:j][i]=='compute02':\n",
    "        compute2.append(df['ID'][i:j][i])\n",
    "    elif df['Compute'][i:j][i]=='compute03':\n",
    "        compute3.append(df['ID'][i:j][i])\n",
    "    elif df['Compute'][i:j][i]=='compute04':\n",
    "        compute4.append(df['ID'][i:j][i])\n",
    "    elif df['Compute'][i:j][i]=='compute05':\n",
    "        compute5.append(df['ID'][i:j][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances=[compute1,compute2,compute3,compute4,compute5]\n",
    "for i in instances:\n",
    "    if(len(i)==0):\n",
    "        i=len(i)\n",
    "        #i=0\n",
    "        #instances.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected\n",
      "[]\n",
      "empty compute\n",
      "[]\n",
      "empty compute\n",
      "[]\n",
      "empty compute\n",
      "[]\n",
      "empty compute\n",
      "[]\n",
      "empty compute\n"
     ]
    }
   ],
   "source": [
    "df2=pd.DataFrame(columns=['time'])\n",
    "df3=pd.DataFrame()\n",
    "presentData=pd.DataFrame(columns=['Compute','data'])\n",
    "l=[]\n",
    "maxVal=[]\n",
    "timestamp=[]\n",
    "com=0\n",
    "k=1\n",
    "compute=['compute01','compute02','compute03','compute04','compute05']\n",
    "flag=0\n",
    "auth_token = connection_to_controller.authorize() #generate Auth token for authenticaion\n",
    "meter_name = \"cpu_util\" #name of the meteric whose statistics has to be determined\n",
    "print(\"Connected\")\n",
    "current_date = datetime.today() \n",
    "previous_date = current_date - timedelta(days=0)\n",
    "for j in instances:\n",
    "    print(j)\n",
    "    if not j:\n",
    "        print(\"empty compute\")\n",
    "        com=com+1\n",
    "        continue\n",
    "    for i in range(len(j)):\n",
    "       \n",
    "        iname = j[i] #instance id\n",
    "        print(iname)\n",
    "        url = \"http://192.168.31.2:8777/v2/meters/{}/statistics\".format(meter_name) #REST api \n",
    "        payload = {'q': [{'field': 'timestamp', 'op': 'ge', 'value': '{}'.format(previous_date)},\n",
    "                         {'field': 'timestamp', 'op': 'lt', 'value': '{}'.format(current_date)}\n",
    "            , {'field': 'resource_id', 'op': 'eq', 'value': '{}'.format(iname)}], 'period': 60}\n",
    "        #payload = {\n",
    "         #    'period': 600}\n",
    "        weekly_data_json = requests.get(url=url, headers={'X-Auth-token': auth_token, 'Content-type': 'application/json'}\n",
    "                               , data=json.dumps(payload)) #GET request to fetch json data from ceilometer\n",
    "        data = weekly_data_json.json() #parsing the json data recieved through the GET request\n",
    "   # timestamp1.append(data[0]['duration_start'])\n",
    "        #print(len(df2))\n",
    "        datafr=pd.DataFrame(data)\n",
    "        #print((datafr).head())\n",
    "        #print(df2)\n",
    "        if datafr.empty:\n",
    "            print(\"No data in compute node \")\n",
    "            df2[i]=0\n",
    "        else:\n",
    "            \n",
    "            #if len(df2['time'])<len(datafr):\n",
    "             #   df2['time']=datafr['duration_start']\n",
    "            #print(datafr['max'][len(datafr)-10:])\n",
    "            df2[i]=datafr['max']\n",
    "    #if flag==1:\n",
    "     #   break\n",
    "    #df2['sum']=0    \n",
    "    df2['sum'] = df2.sum(axis=1)\n",
    "    print(\"sum of all instances in compute \")\n",
    "    #print(df2['sum'].tail())\n",
    "    #df3[0]=df2['time']\n",
    "    if k<=len(instances):\n",
    "        \n",
    "        df2['sum']=df2['sum']/(i+1)\n",
    "        if len(df2['sum'])==0:\n",
    "            \n",
    "            presentData=presentData.append({'Compute':compute[com],'data':0},ignore_index=True)\n",
    "        else:\n",
    "            presentData=presentData.append({'Compute':compute[com],'data':df2['sum'][len(df2)-1]},ignore_index=True)\n",
    "        #df3[k]=df2['sum']\n",
    "        \n",
    "        com=com+1\n",
    "        df2.drop(df2.iloc[:,1:], inplace=True, axis=1)\n",
    "        #del df2['sum']\n",
    "        #print(\"sum after load \")\n",
    "        #print(df2.head())\n",
    "        k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compute</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Compute, data]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presentData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "models=[]\n",
    "for i in presentData['Compute']:\n",
    "    if i=='compute01':\n",
    "        json_file = open('model1.json', 'r')\n",
    "        model1_json = json_file.read()\n",
    "        json_file.close()\n",
    "        model1 = model_from_json(model1_json)\n",
    "        model1.load_weights(\"model1.h5\")\n",
    "        print(\"Loaded model from disk model 1\")\n",
    "        models.append(model1)\n",
    "    elif i=='compute02':\n",
    "        json_file = open('model2.json', 'r')\n",
    "        model2_json = json_file.read()\n",
    "        json_file.close()\n",
    "        model2 = model_from_json(model2_json)\n",
    "        model2.load_weights(\"model2.h5\")\n",
    "        print(\"Loaded model from disk model 2\")\n",
    "        models.append(model2)\n",
    "    elif i=='compute03':\n",
    "        json_file = open('model3.json', 'r')\n",
    "        model3_json = json_file.read()\n",
    "        json_file.close()\n",
    "        model3 = model_from_json(model3_json)\n",
    "        model3.load_weights(\"model3.h5\")\n",
    "        print(\"Loaded model from disk model 3\")\n",
    "        models.append(model3)\n",
    "    elif i=='compute04':\n",
    "        json_file = open('model4.json', 'r')\n",
    "        model4_json = json_file.read()\n",
    "        json_file.close()\n",
    "        model4 = model_from_json(model4_json)\n",
    "        model4.load_weights(\"model4.h5\")\n",
    "        models.append(model4)\n",
    "        print(\"Loaded model from disk model 4\")\n",
    "    elif i=='compute05':\n",
    "        json_file = open('model5.json', 'r')\n",
    "        model5_json = json_file.read()\n",
    "        json_file.close()\n",
    "        model5 = model_from_json(model5_json)\n",
    "        model5.load_weights(\"model5.h5\")\n",
    "        print(\"Loaded model from disk model 5\")\n",
    "        models.append(model5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the next values for each eligible compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=[]\n",
    "for row in range(len(presentData)):\n",
    "    if presentData['Compute'][row]=='compute01':\n",
    "        x=np.array(presentData['data'][row])\n",
    "        x =x.reshape((1,1,1,1))\n",
    "        y=model1.predict(x,verbose=0)\n",
    "        print('Predicted value for compute 1 is :',y)\n",
    "        predict.append(y[0][0])\n",
    "    elif presentData['Compute'][row]=='compute02':\n",
    "        x=np.array(presentData['data'][row])\n",
    "        x =x.reshape((1,1,1,1))\n",
    "        y=model2.predict(x,verbose=0)\n",
    "        print('Predicted value for compute 2 is :',y)\n",
    "        predict.append(y[0][0])\n",
    "    elif presentData['Compute'][row]=='compute03':\n",
    "        x=np.array(presentData['data'][row])\n",
    "        x =x.reshape((1,1,1,1))\n",
    "        y=model3.predict(x,verbose=0)\n",
    "        print('Predicted value for compute 3 is :',y)\n",
    "        predict.append(y[0][0])\n",
    "    elif presentData['Compute'][row]=='compute04':\n",
    "        x=np.array(presentData['data'][row])\n",
    "        x =x.reshape((1,1,1,1))\n",
    "        y=model4.predict(x,verbose=0)\n",
    "        print('Predicted value for compute 4 is :',y)\n",
    "        predict.append(y[0][0])\n",
    "    elif presentData['Compute'][row]=='compute05':\n",
    "        x=np.array(presentData['data'][row])\n",
    "        x =x.reshape((1,1,1,1))\n",
    "        y=model5.predict(x,verbose=0)\n",
    "        print('Predicted value for compute 5 is :',y)\n",
    "        predict.append(y[0][0])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reduction operation 'argmin' not allowed for this dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-63f315ffa86c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meligible\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Available RAM'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midxmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mdesired_host\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meligible\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Compute'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mohammed mudassir\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36midxmin\u001b[1;34m(self, axis, skipna)\u001b[0m\n\u001b[0;32m   8793\u001b[0m         \"\"\"\n\u001b[0;32m   8794\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8795\u001b[1;33m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnanops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanargmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8797\u001b[0m         \u001b[1;31m# indices will always be np.ndarray since axis is not None and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mohammed mudassir\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[0mf_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nan\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                 raise TypeError(\n\u001b[1;32m---> 67\u001b[1;33m                     \u001b[1;34mf\"reduction operation '{f_name}' not allowed for this dtype\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m                 )\n\u001b[0;32m     69\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: reduction operation 'argmin' not allowed for this dtype"
     ]
    }
   ],
   "source": [
    "res=all(i == predict[0] for i in predict)\n",
    "if res:\n",
    "    x=eligible[['Available RAM']].idxmin() \n",
    "    desired_host=eligible['Compute'][x][0]\n",
    "else:\n",
    "    ind=predict.index(max(predict))\n",
    "    desired_host=presentData['Compute'][ind]\n",
    "print(desired_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp='''source creds && nova boot --flavor '''+flavourName+''' --image '''+img+''' --nic net-id=467a06de-fc2c-4fe9-876c-cbec7fe29149 --key-name i4key  --availability-zone nova:'''+desired_host+''' '''+name\n",
    "sshmaster('192.168.31.2',cmp)\n",
    "print('Virtual Machine P2R2 successfully loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision Graph for Scheduling between Best fit and Worst fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best fit (Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if desired_host=='compute01':\n",
    "    fR_pred1=freeRam1-2\n",
    "    fC_pred1=freeCpu1-1\n",
    "elif desired_host=='compute02':\n",
    "    fR_pred2=freeRam2-2\n",
    "    fC_pred2=freeCpu2-1\n",
    "elif desired_host=='compute03':\n",
    "    fR_pred3=freeRam3-2\n",
    "    fC_pred3=freeCpu3-1\n",
    "elif desired_host=='compute04':\n",
    "    fR_pred4=freeRam4-2\n",
    "    fC_pred4=freeCpu4-1\n",
    "elif desired_host=='compute05':\n",
    "    fR_pred5=freeRam5-2\n",
    "    fC_pred5=freeCpu5-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worst fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if desired_host=='compute01':\n",
    "    fR_fit1=freeRam1-2\n",
    "    fC_fit1=freeCpu1-1\n",
    "elif desired_host=='compute02':\n",
    "    fR_fit2=freeRam2-2\n",
    "    fC_fit2=freeCpu2-1\n",
    "elif desired_host=='compute03':\n",
    "    fR_fit3=freeRam3-2\n",
    "    fC_fit3=freeCpu3-1\n",
    "elif desired_host=='compute04':\n",
    "    fR_fit4=freeRam4-2\n",
    "    fC_fit4=freeCpu4-1\n",
    "elif desired_host=='compute05':\n",
    "    fR_fit5=freeRam5-2\n",
    "    fC_fit5=freeCpu5-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "totalRam=[4,8,8,8,8]\n",
    "allocatedRam=[4,8,6,6,4]\n",
    "labels = ['Compute 1', 'Compute 2', 'Compute 3', 'Compute 4', 'Compute 5']\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, totalRam, width, label='Total RAM')\n",
    "rects2 = ax.bar(x + width/2, allocatedRam, width, label='Occupied RAM')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Allocation using Worst fit (Default)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalRam=[4,8,8,8,8]\n",
    "allocatedRam=[4,8,4,8,4]\n",
    "labels = ['Compute 1', 'Compute 2', 'Compute 3', 'Compute 4', 'Compute 5']\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, totalRam, width, label='Total RAM')\n",
    "rects2 = ax.bar(x + width/2, allocatedRam, width, label='Occupied RAM')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Allocation using Best fit (Prediction)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalCpu=[2,4,2,4,2]\n",
    "allocatedCpu=[2,4,2,3,1]\n",
    "labels = ['Compute 1', 'Compute 2', 'Compute 3', 'Compute 4', 'Compute 5']\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, totalCpu, width, label='Total VCPUs')\n",
    "rects2 = ax.bar(x + width/2, allocatedCpu, width, label='Occupied VCPUs')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Allocation using Best fit (Default) ')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalCpu=[2,4,2,4,2]\n",
    "allocatedCpu=[2,4,1,4,1]\n",
    "labels = ['Compute 1', 'Compute 2', 'Compute 3', 'Compute 4', 'Compute 5']\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, totalCpu, width, label='Total VCPUs')\n",
    "rects2 = ax.bar(x + width/2, allocatedCpu, width, label='Occupied VCPUs')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Allocation using Best fit (Prediction) ')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "availabelCpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
